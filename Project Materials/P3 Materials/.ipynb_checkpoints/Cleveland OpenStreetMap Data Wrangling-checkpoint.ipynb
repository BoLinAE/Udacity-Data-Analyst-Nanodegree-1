{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OpenStreetMap](https://www.openstreetmap.org/#map=11/41.4980/-81.7070) is a user-generated map of the entire world, freely available to download. \n",
    "The data extract of Cleveland used for this project was downloaded from [Mapzen Metro Extracts](https://mapzen.com/data/metro-extracts/metro/cleveland_ohio/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step was to download the map as an XML file. The original file was nearly 5.5 million lines long, which meant that it would be unwieldy to process the entire file every time. I decided to create sample files for testing out my auditing scripts and cleaning. I wanted a smaller file to test run functions and then an intermediate file I could use for identifying the most common problems prior to cleaning the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orginal file contains the following breakdown of top-level elements: {'way': 189248, 'node': 1795742, 'relation': 3732}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breakdown of top-level elements for the three file sizes is summarized in the following table:\n",
    "\n",
    "|                     \t    | 'node'  \t| 'way'  \t| 'relation' \t| File Size (MB) \t|\n",
    "|-----------------------\t|---------\t|--------\t|------------\t|----------------\t|\n",
    "| __Full file__          \t| 1795742 \t| 189248 \t| 3732       \t|      392.6     \t|\n",
    "| __Intermediate sample__ \t| 179575  \t| 18924  \t| 374        \t|      39.9      \t|\n",
    "| __Small sample__        \t| 17958   \t| 1892   \t| 38         \t|       3.9      \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall Approach\n",
    "Being in possession of a large dataset can be both exciting and intimidating! There are numerous possiblities, but the sheer amount of data can be overwhelming. Before I officially began any data wrangling, I wanted to have a step-by-step plan to guide my actions in order to efficiently go through the process of cleaning the data. I decided that the following approach, adapted from the Udacity course on Data Wrangling was a solid guide:\n",
    "\n",
    "1. Audit the data: identify errors/missing data in the XML data\n",
    "2. Create a data cleaning plan based on the audit\n",
    "    * Identify the causes of any \"dirty\" or inconsistent data \n",
    "    * Develop a set of corrective cleaning actions and test on a small sample of the XML data\n",
    "3. Implement the data cleaning plan: run scripts and transfer the cleaned data to .csv files\n",
    "4. Manually correct as necessary: import the data from .csv to SQL and perform SQL queries on the data to identify any further inconsistencies that would necessitate returning to step 2. \n",
    "\n",
    "Data wrangling is an iterative procedure, and as such, I expected that I might need to cycle through these steps several times. However, I knew that having a clear outline of the procedure to follow would save me untold hours of work and confusion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auditing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five main aspects of data quality to consider when auditing a dataset:\n",
    "1. Validity: Does the data conform to a schema (standard format)?\n",
    "2. Accuracy: Does the data conform to reality or a trusted external source?\n",
    "3. Completeness: Are all records present?\n",
    "4. Consistency: Is data in a field or across a row in logical agreement?\n",
    "5. Uniformity: Are the same units used for a given field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_file = 'amenitiesSource.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bar\n",
      " bbq\n",
      " biergarten\n",
      " cafe\n",
      " drinking_water\n",
      " fast_food\n",
      " food_court\n",
      " ice_cream\n",
      " pub\n",
      " restaurant\n",
      " college\n",
      " kindergarten\n",
      " library\n",
      " public_bookcase\n",
      " school\n",
      " music_school\n",
      " driving_school\n",
      " language_school\n",
      " university\n",
      " bicycle_parking\n",
      " bicycle_repair_station\n",
      " bicycle_rental\n",
      " boat_sharing\n",
      " bus_station\n",
      " car_rental\n",
      " car_sharing\n",
      " car_wash\n",
      " charging_station\n",
      " ferry_terminal\n",
      " fuel\n",
      " grit_bin\n",
      " motorcycle_parking\n",
      " parking\n",
      " parking_entrance\n",
      " parking_space\n",
      " taxi\n",
      " atm\n",
      " bank\n",
      " bureau_de_change\n",
      " baby_hatch\n",
      " clinic\n",
      " dentist\n",
      " doctors\n",
      " hospital\n",
      " nursing_home\n",
      " pharmacy\n",
      " social_facility\n",
      " veterinary\n",
      " healthcare\n",
      " blood_donation\n",
      " arts_centre\n",
      " brothel\n",
      " casino\n",
      " cinema\n",
      " community_centre\n",
      " fountain\n",
      " gambling\n",
      " nightclub\n",
      " amenity=stripclub\n",
      " planetarium\n",
      " social_centre\n",
      " stripclub\n",
      " studio\n",
      " swingerclub\n",
      " theatre\n",
      " animal_boarding\n",
      " animal_shelter\n",
      " baking_oven\n",
      " bench\n",
      " clock\n",
      " courthouse\n",
      " coworking_space\n",
      " crematorium\n",
      " crypt\n",
      " dive_centre\n",
      " dojo\n",
      " embassy\n",
      " fire_station\n",
      "Tag:leisure=firepit\n",
      " game_feeding\n",
      " grave_yard\n",
      " hunting_stand\n",
      " internet_cafe\n",
      " kneipp_water_cure\n",
      " marketplace\n",
      " photo_booth\n",
      " place_of_worship\n",
      "the article\n",
      " police\n",
      " post_box\n",
      " post_office\n",
      " prison\n",
      " ranger_station\n",
      " recycling\n",
      " rescue_station\n",
      " shelter\n",
      " shower\n",
      " table\n",
      " telephone\n",
      " toilets\n",
      " townhall\n",
      " vending_machine\n",
      " waste_basket\n",
      " waste_disposal\n",
      " waste_transfer_station\n",
      " watering_place\n",
      " water_point\n",
      " user defined\n",
      "Taginfo\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse(source_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "for table in root.iter('table'):\n",
    "    if table.attrib['class'] == 'wikitable':\n",
    "        for row in table:\n",
    "            for data in row.findall('td'):\n",
    "                for element in data:\n",
    "                    if element.tag == 'a':\n",
    "                        if element.text:\n",
    "                            print(element.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
